{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "glove.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTZNq4F6P-ud"
      },
      "source": [
        "# Importing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avhgFke8ehEi"
      },
      "source": [
        "import keras\n",
        "\n",
        "from keras.datasets import imdb\n",
        "\n",
        "from keras.layers import LSTM, Activation, Dropout, Dense, Input\n",
        "from keras.layers.embeddings import Embedding\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NGhYtyUe2cq",
        "outputId": "a10a0289-1c85-428f-8972-3a5230227972"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29Ak2QQ9ejcj"
      },
      "source": [
        "data = pd.read_excel('/content/drive/My Drive/dataset/dataset.xlsx', engine='openpyxl')\n",
        "\n",
        "data['Text'] = data['Text'].str.lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSzCu4dAQMeB"
      },
      "source": [
        "# Dataset cleaning and analysing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJx-rX2rfI3u"
      },
      "source": [
        "stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \n",
        "             \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\",\n",
        "             \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \n",
        "             \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\",\n",
        "             \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\",\n",
        "             \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \n",
        "             \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\",\n",
        "             \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\",\n",
        "             \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\",\n",
        "             \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\",\n",
        "             \"your\", \"yours\", \"yourself\", \"yourselves\" ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VL5fXA9cfMwX"
      },
      "source": [
        "def remove_stopwords(data):\n",
        "  data['review without stopwords'] = data['Text'].apply(lambda x : ' '.join([word for word in x.split() if word not in (stopwords)]))\n",
        "  return data\n",
        "\n",
        "def remove_tags(string):\n",
        "    result = re.sub('<.*?>','',string)\n",
        "    return result\n",
        "    \n",
        "data_without_stopwords = remove_stopwords(data)\n",
        "data_without_stopwords['clean_review']= data_without_stopwords['review without stopwords'].apply(lambda cw : remove_tags(cw))\n",
        "data_without_stopwords['clean_review'] = data_without_stopwords['clean_review'].str.replace('[{}]'.format(string.punctuation), ' ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "oudl0eDWftJd",
        "outputId": "e4c7176e-85e6-4797-e11b-46c5882a8133"
      },
      "source": [
        "data_without_stopwords.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>URL</th>\n",
              "      <th>Text</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>review without stopwords</th>\n",
              "      <th>clean_review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>http://www.imdb.com/title/tt0210075/usercomments</td>\n",
              "      <td>girlfight follows a project dwelling new york ...</td>\n",
              "      <td>POS</td>\n",
              "      <td>girlfight follows project dwelling new york hi...</td>\n",
              "      <td>girlfight follows project dwelling new york hi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>http://www.imdb.com/title/tt0337640/usercomments</td>\n",
              "      <td>hollywood north is an euphemism from the movie...</td>\n",
              "      <td>POS</td>\n",
              "      <td>hollywood north euphemism movie industry went ...</td>\n",
              "      <td>hollywood north euphemism movie industry went ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>http://www.imdb.com/title/tt0303549/usercomments</td>\n",
              "      <td>that '70s show is definitely the funniest show...</td>\n",
              "      <td>POS</td>\n",
              "      <td>'70s show definitely funniest show currently t...</td>\n",
              "      <td>70s show definitely funniest show currently t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>http://www.imdb.com/title/tt0716825/usercomments</td>\n",
              "      <td>9/10- 30 minutes of pure holiday terror. okay,...</td>\n",
              "      <td>POS</td>\n",
              "      <td>9/10- 30 minutes pure holiday terror. okay, no...</td>\n",
              "      <td>9 10  30 minutes pure holiday terror  okay  no...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>http://www.imdb.com/title/tt0182225/usercomments</td>\n",
              "      <td>a series of random, seemingly insignificant th...</td>\n",
              "      <td>POS</td>\n",
              "      <td>series random, seemingly insignificant thefts ...</td>\n",
              "      <td>series random  seemingly insignificant thefts ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                URL  ...                                       clean_review\n",
              "0  http://www.imdb.com/title/tt0210075/usercomments  ...  girlfight follows project dwelling new york hi...\n",
              "1  http://www.imdb.com/title/tt0337640/usercomments  ...  hollywood north euphemism movie industry went ...\n",
              "2  http://www.imdb.com/title/tt0303549/usercomments  ...   70s show definitely funniest show currently t...\n",
              "3  http://www.imdb.com/title/tt0716825/usercomments  ...  9 10  30 minutes pure holiday terror  okay  no...\n",
              "4  http://www.imdb.com/title/tt0182225/usercomments  ...  series random  seemingly insignificant thefts ...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZah_hsvfZKP"
      },
      "source": [
        "reviews_list = []\n",
        "for i in range(len(data_without_stopwords['clean_review'])):\n",
        "  reviews_list.append(data_without_stopwords['clean_review'][i])\n",
        " \n",
        "sentiment = data_without_stopwords['Sentiment']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OlKdW-TR6ZU"
      },
      "source": [
        "y = np.array(list(map(lambda x: 1 if x==\"POS\" else 0, sentiment)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Crg7mwhnR_Wz"
      },
      "source": [
        "### Data split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9B2LohAgl4k"
      },
      "source": [
        "X_train, X_test,Y_train, Y_test = train_test_split(reviews_list, y, test_size=0.2, random_state = 45)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpEOD86bSB_Y"
      },
      "source": [
        "### Data Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IeQmFRwgqI8"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "words_to_index = tokenizer.word_index\n",
        "#type(words_to_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isPi5LYDSXGr"
      },
      "source": [
        "# Making Global Vector Map"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYrnkzA-g2if"
      },
      "source": [
        "def read_glove_vector(glove_vec):\n",
        "  with open(glove_vec, 'r', encoding='UTF-8') as f:\n",
        "    words = set()\n",
        "    word_to_vec_map = {}\n",
        "    for line in f:\n",
        "      w_line = line.split()\n",
        "      curr_word = w_line[0]\n",
        "      word_to_vec_map[curr_word] = np.array(w_line[1:], dtype=np.float64)\n",
        "  return word_to_vec_map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlwtMOkouiKZ"
      },
      "source": [
        "Download and mount the file glove.6B.50d.txt\n",
        "\n",
        "https://www.kaggle.com/watts2/glove6b50dtxt\n",
        " \n",
        "https://nlp.stanford.edu/projects/glove/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwnyzSlwu6Eb"
      },
      "source": [
        "# !unzip '/content/drive/My Drive/dataset/archive.zip' -d '/content/drive/My Drive/dataset/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Av9P7mU_g9kB"
      },
      "source": [
        "word_to_vec_map = read_glove_vector('/content/drive/My Drive/dataset/glove.6B.50d.txt')\n",
        "maxLen = 150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n53tQBTa0cLb",
        "outputId": "246e0b41-fb6a-44c8-d980-bfbea6f09a94"
      },
      "source": [
        "word_to_vec_map['moon'].shape[0]\n",
        "len(words_to_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uLsjb2pz2BX"
      },
      "source": [
        "vocab_len = len(words_to_index)\n",
        "embed_vector_len = word_to_vec_map['moon'].shape[0]\n",
        "\n",
        "emb_matrix = np.zeros((vocab_len, embed_vector_len))\n",
        "\n",
        "for word, index in words_to_index.items():\n",
        "  embedding_vector = word_to_vec_map.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    emb_matrix[index - 1, :] = embedding_vector\n",
        "\n",
        "embedding_layer = Embedding(input_dim=vocab_len, output_dim=embed_vector_len, input_length=maxLen, weights = [emb_matrix], trainable=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4EykN1tUECO"
      },
      "source": [
        "### Defining Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ga--8-vs1beE"
      },
      "source": [
        "def movie_rating(input_shape):\n",
        "  X_indices = Input(input_shape)\n",
        "  embeddings = embedding_layer(X_indices)\n",
        "\n",
        "  X = LSTM(128, return_sequences=True)(embeddings)\n",
        "  X = Dropout(0.6)(X)\n",
        "  X = LSTM(128, return_sequences=True)(X)\n",
        "  X = Dropout(0.6)(X)\n",
        "  X = LSTM(128)(X)\n",
        "  X = Dense(1, activation='sigmoid')(X)\n",
        "\n",
        "  model = Model(inputs=X_indices, outputs=X)\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwEC4-pH1i5g"
      },
      "source": [
        "X_train_indices = tokenizer.texts_to_sequences(X_train)\n",
        "X_train_indices = pad_sequences(X_train_indices, maxlen=maxLen, padding='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aEkYD8B8HZS"
      },
      "source": [
        "X_test_indices = tokenizer.texts_to_sequences(X_test)\n",
        "X_test_indices = pad_sequences(X_test_indices, maxlen=maxLen, padding='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyDTqIFl48Lt",
        "outputId": "67e21a7b-6436-4ca0-d39c-c146192845d6"
      },
      "source": [
        "# X_train_indices.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1599, 150)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zH4PslyZ6JCT"
      },
      "source": [
        "model = movie_rating(X_train_indices.shape[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peSi6Ftt1nJy",
        "outputId": "b43b326f-75bc-44e7-ac76-8ed3f680efa7"
      },
      "source": [
        "adam = keras.optimizers.Adam(learning_rate = 0.0001)\n",
        "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train_indices, Y_train, batch_size=64, epochs=15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "25/25 [==============================] - 30s 970ms/step - loss: 0.6958 - accuracy: 0.4747\n",
            "Epoch 2/15\n",
            "25/25 [==============================] - 24s 974ms/step - loss: 0.6905 - accuracy: 0.5255\n",
            "Epoch 3/15\n",
            "25/25 [==============================] - 24s 966ms/step - loss: 0.6921 - accuracy: 0.5104\n",
            "Epoch 4/15\n",
            "25/25 [==============================] - 25s 990ms/step - loss: 0.6918 - accuracy: 0.4940\n",
            "Epoch 5/15\n",
            "25/25 [==============================] - 25s 987ms/step - loss: 0.6904 - accuracy: 0.5258\n",
            "Epoch 6/15\n",
            "25/25 [==============================] - 25s 985ms/step - loss: 0.6926 - accuracy: 0.5140\n",
            "Epoch 7/15\n",
            "25/25 [==============================] - 25s 993ms/step - loss: 0.6900 - accuracy: 0.5174\n",
            "Epoch 8/15\n",
            "25/25 [==============================] - 25s 993ms/step - loss: 0.6880 - accuracy: 0.5206\n",
            "Epoch 9/15\n",
            "25/25 [==============================] - 25s 1s/step - loss: 0.6907 - accuracy: 0.5075\n",
            "Epoch 10/15\n",
            "25/25 [==============================] - 24s 969ms/step - loss: 0.6911 - accuracy: 0.5120\n",
            "Epoch 11/15\n",
            "25/25 [==============================] - 24s 975ms/step - loss: 0.6858 - accuracy: 0.5511\n",
            "Epoch 12/15\n",
            "25/25 [==============================] - 25s 983ms/step - loss: 0.6921 - accuracy: 0.5084\n",
            "Epoch 13/15\n",
            "25/25 [==============================] - 25s 986ms/step - loss: 0.6879 - accuracy: 0.5401\n",
            "Epoch 14/15\n",
            "25/25 [==============================] - 25s 1s/step - loss: 0.6883 - accuracy: 0.5135\n",
            "Epoch 15/15\n",
            "25/25 [==============================] - 25s 997ms/step - loss: 0.6870 - accuracy: 0.5224\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f62a5684e50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcmxvmlf6wLT",
        "outputId": "8425c5fd-ef13-4dfd-efac-faeed4e4b384"
      },
      "source": [
        "model.evaluate(X_test_indices, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13/13 [==============================] - 3s 141ms/step - loss: 0.6923 - accuracy: 0.5275\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6922664642333984, 0.5274999737739563]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXpS0_k1U8fD"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9C0HowB6zrh",
        "outputId": "4611302f-9438-465b-e711-669203d82269"
      },
      "source": [
        "preds = model.predict(X_test_indices)\n",
        "n = np.random.randint(0,len(X_test))\n",
        "# X_test[n]\n",
        "if preds[n] > 0.5:\n",
        "  print('predicted sentiment : positive')\n",
        "else: \n",
        "  print('precicted sentiment : negative')\n",
        "\n",
        "if (Y_test[n] == 1):\n",
        "  print('correct sentiment : positive')\n",
        "else:\n",
        "  print('correct sentiment : negative')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "precicted sentiment : negative\n",
            "correct sentiment : negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mecZMJKi8wGB"
      },
      "source": [
        "Y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyvGjpE78yah"
      },
      "source": [
        "preds.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caFgTMDj9BOy"
      },
      "source": [
        "Y_test[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ju_A1ZHw9HAl"
      },
      "source": [
        "preds[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Vkqz0DQ9WlY"
      },
      "source": [
        "def get_pred(preds):\n",
        "  if preds > 0.5:\n",
        "    return 1\n",
        "  else: \n",
        "    return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvHHHa_p9Tvp"
      },
      "source": [
        "predictions = [get_pred(x) for x in preds]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5GWOmre8bxh",
        "outputId": "a769d333-f64f-4dbc-a9f2-cfeb151676d5"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(Y_test, predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.35      0.41       187\n",
            "           1       0.54      0.69      0.61       213\n",
            "\n",
            "    accuracy                           0.53       400\n",
            "   macro avg       0.52      0.52      0.51       400\n",
            "weighted avg       0.52      0.53      0.51       400\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}